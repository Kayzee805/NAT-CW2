{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "import pso\n",
    "import ann\n",
    "\n",
    "np.random.seed(6663)\n",
    "def dim_weights(shape):\n",
    "    dim = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        dim = dim + (shape[i] + 1) * shape[i+1]\n",
    "    return dim\n",
    "\n",
    "def weights_to_vector(weights):\n",
    "    w = np.asarray([])\n",
    "    for i in range(len(weights)):\n",
    "        v = weights[i].flatten()\n",
    "        w = np.append(w, v)\n",
    "    return w\n",
    "\n",
    "def vector_to_weights(vector, shape):\n",
    "    weights = []\n",
    "    idx = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        r = shape[i+1]\n",
    "        c = shape[i] + 1\n",
    "        idx_min = idx\n",
    "        idx_max = idx + r*c\n",
    "        W = vector[idx_min:idx_max].reshape(r,c)\n",
    "        weights.append(W)\n",
    "    return weights\n",
    "\n",
    "def eval_neural_network(weights, shape, X, y):\n",
    "    mse = np.asarray([])\n",
    "    for w in weights:\n",
    "        weights = vector_to_weights(w, shape)\n",
    "        nn = ann.MultiLayerPerceptron(shape, weights=weights)\n",
    "        y_pred = nn.run(X)\n",
    "        mse = np.append(mse, sklearn.metrics.mean_squared_error(np.atleast_2d(y), y_pred))\n",
    "    return mse\n",
    "\n",
    "def print_best_particle(best_particle):\n",
    "    print(\"New best particle found at iteration #{i} with mean squared error: {score}\".format(i=best_particle[0], score=best_particle[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#just xy error = 0.22938741634873416\n",
    "#with sinx sin y error = 0.2325498216710004\n",
    "#with sin and sq error = 0.21790465807135315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sine(X):\n",
    "    return np.sin(X)\n",
    "\n",
    "\n",
    "#loading Starts here\n",
    "\n",
    "def sq(X):\n",
    "    return np.power(X,2)\n",
    "num_classes = 2\n",
    "f = open(\"two_spirals.dat\",\"r\")\n",
    "data = np.loadtxt(f)\n",
    "\n",
    "# X = data[:,0:2]+sine(data[:,0:2])+sq(data[:,0:2])\n",
    "# #X = data[:,0:2]+sine(data[:,0:2])\n",
    "# #X = data[:,0:2]\n",
    "# y = data[:,2]\n",
    "# y = y.astype(int)\n",
    "# train_test_split = int(0.5*(len(X)))\n",
    "# #print(train_test_split)\n",
    "# X_train,X_test = X[:train_test_split],X[train_test_split:]\n",
    "# y_train,y_test = y[:train_test_split],y[train_test_split:]\n",
    "\n",
    "# print(len(X))\n",
    "# print(y.size)\n",
    "# print(y_train.size)\n",
    "# print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "264\n",
      "264\n",
      "132\n",
      "132\n",
      "[ 4.47485    -0.89004    -0.97192002 -0.77709692 20.02428252  0.7921712 ]\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0:2]\n",
    "test = np.zeros(shape=(len(X),6))\n",
    "\n",
    "for i in range(len(X)):\n",
    "   # print(X[i])\n",
    "    #print(sine(X[i]))\n",
    "    test[i] = np.append(X[i],[sine(X[i]),sq(X[i])])\n",
    "X=test\n",
    "y = data[:,2]\n",
    "y = y.astype(int)\n",
    "train_test_split = int(0.5*(len(y)))\n",
    "#print(train_test_split)\n",
    "X_train,X_test = X[:train_test_split],X[train_test_split:]\n",
    "y_train,y_test = y[:train_test_split],y[train_test_split:]\n",
    "\n",
    "\n",
    "print(len(test))\n",
    "print(len(X))\n",
    "print(y.size)\n",
    "print(y_train.size)\n",
    "print(y_test.size)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "print(y_train.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs =  6\n",
      "y test shap e=  (132,)\n",
      "y true shape =  (264, 2)\n",
      "y test true shape =  (132, 2)\n",
      "(132, 6)\n",
      "(132, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load MNIST digits from sklearn\n",
    "\n",
    "# num_classes = 10\n",
    "# mnist = sklearn.datasets.load_digits(num_classes)\n",
    "# X, X_test, y, y_test = sklearn.model_selection.train_test_split(mnist.data, mnist.target)\n",
    "\n",
    "num_inputs = X.shape[1]\n",
    "print(\"Number of inputs = \",num_inputs)\n",
    "y_true = np.zeros((len(y), num_classes))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y_true[i, y[i]] = 1\n",
    "\n",
    "y_test_true = np.zeros((len(y_test), num_classes))\n",
    "for i in range(len(y_test)):\n",
    "    y_test_true[i, y_test[i]] = 1\n",
    "\n",
    "\n",
    "print(\"y test shap e= \", y_test.shape)\n",
    "print(\"y true shape = \",y_true.shape)\n",
    "print(\"y test true shape = \",y_test_true.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best particle found at iteration #0 with mean squared error: 0.46538670498383516\n",
      "New best particle found at iteration #100 with mean squared error: 0.18982380631122153\n",
      "New best particle found at iteration #200 with mean squared error: 0.1477192221861748\n",
      "New best particle found at iteration #300 with mean squared error: 0.10881328171956621\n",
      "New best particle found at iteration #400 with mean squared error: 0.09555725070094007\n",
      "New best particle found at iteration #500 with mean squared error: 0.08537659352070871\n",
      "New best particle found at iteration #600 with mean squared error: 0.08254222259214733\n",
      "New best particle found at iteration #700 with mean squared error: 0.07967976264133655\n",
      "New best particle found at iteration #800 with mean squared error: 0.07701945958643286\n",
      "New best particle found at iteration #900 with mean squared error: 0.07516024475241846\n",
      "New best particle found at iteration #1000 with mean squared error: 0.0740571022769487\n",
      "New best particle found at iteration #1100 with mean squared error: 0.07232073290483015\n",
      "New best particle found at iteration #1200 with mean squared error: 0.07090832759438276\n",
      "New best particle found at iteration #1300 with mean squared error: 0.06993109385972184\n",
      "New best particle found at iteration #1400 with mean squared error: 0.06013780318458349\n",
      "New best particle found at iteration #1500 with mean squared error: 0.05831539474097016\n",
      "New best particle found at iteration #1600 with mean squared error: 0.05697279701928233\n",
      "New best particle found at iteration #1700 with mean squared error: 0.0552745897410548\n",
      "New best particle found at iteration #1800 with mean squared error: 0.0545141177119978\n",
      "New best particle found at iteration #1900 with mean squared error: 0.0540750343633995\n",
      "New best particle found at iteration #2000 with mean squared error: 0.05356998558890722\n",
      "New best particle found at iteration #2100 with mean squared error: 0.05280013253075306\n",
      "New best particle found at iteration #2200 with mean squared error: 0.05196325697468715\n",
      "New best particle found at iteration #2300 with mean squared error: 0.05142741827159496\n",
      "New best particle found at iteration #2400 with mean squared error: 0.051106937462407374\n",
      "New best particle found at iteration #2500 with mean squared error: 0.05081488327900807\n",
      "New best particle found at iteration #2600 with mean squared error: 0.05049904335560954\n",
      "New best particle found at iteration #2700 with mean squared error: 0.050205391892220355\n",
      "New best particle found at iteration #2800 with mean squared error: 0.049953380850787245\n",
      "New best particle found at iteration #2900 with mean squared error: 0.04952940513695673\n",
      "New best particle found at iteration #3000 with mean squared error: 0.049295155071622694\n",
      "New best particle found at iteration #3100 with mean squared error: 0.04903650917916552\n",
      "New best particle found at iteration #3200 with mean squared error: 0.04851886204464085\n",
      "New best particle found at iteration #3300 with mean squared error: 0.04833009866569902\n",
      "New best particle found at iteration #3400 with mean squared error: 0.04817988701556075\n",
      "New best particle found at iteration #3500 with mean squared error: 0.04795696431988201\n",
      "New best particle found at iteration #3600 with mean squared error: 0.04781259014521557\n",
      "New best particle found at iteration #3700 with mean squared error: 0.04765501979935037\n",
      "New best particle found at iteration #3800 with mean squared error: 0.04752734585150232\n",
      "New best particle found at iteration #3900 with mean squared error: 0.047436493172146606\n",
      "New best particle found at iteration #4000 with mean squared error: 0.04738682917635751\n",
      "New best particle found at iteration #4100 with mean squared error: 0.046936579201934836\n",
      "New best particle found at iteration #4200 with mean squared error: 0.04670397716989197\n",
      "New best particle found at iteration #4300 with mean squared error: 0.046519833836523854\n",
      "New best particle found at iteration #4400 with mean squared error: 0.04638379416951677\n",
      "New best particle found at iteration #4500 with mean squared error: 0.046323037761642406\n",
      "New best particle found at iteration #4600 with mean squared error: 0.04614457803401538\n",
      "New best particle found at iteration #4700 with mean squared error: 0.04603638889865861\n",
      "New best particle found at iteration #4800 with mean squared error: 0.045897833908016994\n",
      "New best particle found at iteration #4900 with mean squared error: 0.04580192009295051\n",
      "New best particle found at iteration #5000 with mean squared error: 0.0456793505676581\n",
      "New best particle found at iteration #5100 with mean squared error: 0.04558105756885352\n",
      "New best particle found at iteration #5200 with mean squared error: 0.04552823498421975\n",
      "New best particle found at iteration #5300 with mean squared error: 0.04542179398508862\n",
      "New best particle found at iteration #5400 with mean squared error: 0.04535376785048753\n",
      "New best particle found at iteration #5500 with mean squared error: 0.045290102736981225\n",
      "New best particle found at iteration #5600 with mean squared error: 0.04519522806201002\n",
      "New best particle found at iteration #5700 with mean squared error: 0.045155180737111944\n",
      "New best particle found at iteration #5800 with mean squared error: 0.04509145449086909\n",
      "New best particle found at iteration #5900 with mean squared error: 0.04498008997928222\n",
      "New best particle found at iteration #6000 with mean squared error: 0.04494762454504895\n",
      "New best particle found at iteration #6100 with mean squared error: 0.04489696355964464\n",
      "New best particle found at iteration #6200 with mean squared error: 0.04483314478203256\n",
      "New best particle found at iteration #6300 with mean squared error: 0.044767343918837736\n",
      "New best particle found at iteration #6400 with mean squared error: 0.04473352912000772\n",
      "New best particle found at iteration #6500 with mean squared error: 0.04469748335372651\n",
      "New best particle found at iteration #6600 with mean squared error: 0.044644958442680356\n",
      "New best particle found at iteration #6700 with mean squared error: 0.044621653526803924\n",
      "New best particle found at iteration #6800 with mean squared error: 0.044531245070545344\n",
      "New best particle found at iteration #6900 with mean squared error: 0.044483251336860805\n",
      "New best particle found at iteration #7000 with mean squared error: 0.044451523735714885\n",
      "New best particle found at iteration #7100 with mean squared error: 0.04442188996505542\n",
      "New best particle found at iteration #7200 with mean squared error: 0.0443718101260819\n",
      "New best particle found at iteration #7300 with mean squared error: 0.04435255907705482\n",
      "New best particle found at iteration #7400 with mean squared error: 0.04433597940552785\n",
      "New best particle found at iteration #7500 with mean squared error: 0.04432590936494795\n",
      "New best particle found at iteration #7600 with mean squared error: 0.04431349692309905\n",
      "New best particle found at iteration #7700 with mean squared error: 0.04430083670410949\n",
      "New best particle found at iteration #7800 with mean squared error: 0.04429252418701124\n",
      "New best particle found at iteration #7900 with mean squared error: 0.04420282591451593\n",
      "New best particle found at iteration #8000 with mean squared error: 0.044173953703015356\n",
      "New best particle found at iteration #8100 with mean squared error: 0.04416291634521092\n",
      "New best particle found at iteration #8200 with mean squared error: 0.04414829665635287\n",
      "New best particle found at iteration #8300 with mean squared error: 0.044132990426425475\n",
      "New best particle found at iteration #8400 with mean squared error: 0.04412601375621873\n",
      "New best particle found at iteration #8500 with mean squared error: 0.04410583794165198\n",
      "New best particle found at iteration #8600 with mean squared error: 0.04409577807668501\n",
      "New best particle found at iteration #8700 with mean squared error: 0.04408287440810152\n",
      "New best particle found at iteration #8800 with mean squared error: 0.04406984619562397\n",
      "New best particle found at iteration #8900 with mean squared error: 0.044045381836028054\n",
      "New best particle found at iteration #9000 with mean squared error: 0.04403002675984634\n",
      "New best particle found at iteration #9100 with mean squared error: 0.04401755622248616\n",
      "New best particle found at iteration #9200 with mean squared error: 0.04400832206732288\n",
      "New best particle found at iteration #9300 with mean squared error: 0.04400279497513042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best particle found at iteration #9400 with mean squared error: 0.0439966154292788\n",
      "New best particle found at iteration #9500 with mean squared error: 0.04399109082367357\n",
      "New best particle found at iteration #9600 with mean squared error: 0.043960980550193735\n",
      "New best particle found at iteration #9700 with mean squared error: 0.043949705568744724\n",
      "New best particle found at iteration #9800 with mean squared error: 0.04392585702181378\n",
      "New best particle found at iteration #9900 with mean squared error: 0.043909712159917146\n",
      "New best particle found at iteration #10000 with mean squared error: 0.043883261772791844\n",
      "MSE score = 0.05303030303030303\n",
      "Accuracy score =  0.9242424242424242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        66\n",
      "           1       0.90      0.98      0.94        66\n",
      "\n",
      "   micro avg       0.93      0.97      0.95       132\n",
      "   macro avg       0.93      0.97      0.95       132\n",
      "weighted avg       0.93      0.97      0.95       132\n",
      " samples avg       0.95      0.97      0.95       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up\n",
    "\n",
    "shape = (num_inputs, 8, num_classes)\n",
    "\n",
    "cost_func = functools.partial(eval_neural_network, shape=shape, X=X, y=y_true.T)\n",
    "\n",
    "swarm = pso.ParticleSwarm(cost_func, num_dimensions=dim_weights(shape), num_particles=30,chi=0.72984 ,phi_p=2.05,phi_g=2.05)\n",
    "\n",
    "# Train...\n",
    "i = 0\n",
    "best_scores = [(i, swarm.best_score)]\n",
    "print_best_particle(best_scores[-1])\n",
    "while swarm.best_score>1e-6 and i<10000:\n",
    "    swarm._update()\n",
    "    i = i+1\n",
    "    #print(\"index = \",i)\n",
    "    if i%100==0 and swarm.best_score < best_scores[-1][1]:\n",
    "        best_scores.append((i, swarm.best_score))\n",
    "        print_best_particle(best_scores[-1])\n",
    "\n",
    "# Test...\n",
    "best_weights = vector_to_weights(swarm.g, shape)\n",
    "best_nn = ann.MultiLayerPerceptron(shape, weights=best_weights)\n",
    "\n",
    "y_test_pred = np.round(best_nn.run(X_test))\n",
    "print(\"MSE score =\",sklearn.metrics.mean_squared_error(y_test_true,y_test_pred.T))\n",
    "print(\"Accuracy score = \",sklearn.metrics.accuracy_score(y_test_true,y_test_pred.T))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test_true, y_test_pred.T))\n",
    "\n",
    "# #MES score = 0.30303030303030304\n",
    "# Accuracy score =  0.5606060606060606\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the brute force method figure out the optimal functions\n",
    "\n",
    "then use the same functions in PSO and compare it with base line\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

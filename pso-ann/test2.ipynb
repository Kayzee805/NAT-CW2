{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "\n",
    "import pso\n",
    "import ann\n",
    "\n",
    "np.random.seed(6663)\n",
    "def dim_weights(shape):\n",
    "    dim = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        dim = dim + (shape[i] + 1) * shape[i+1]\n",
    "    return dim\n",
    "\n",
    "def weights_to_vector(weights):\n",
    "    w = np.asarray([])\n",
    "    for i in range(len(weights)):\n",
    "        v = weights[i].flatten()\n",
    "        w = np.append(w, v)\n",
    "    return w\n",
    "\n",
    "def vector_to_weights(vector, shape):\n",
    "    weights = []\n",
    "    idx = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        r = shape[i+1]\n",
    "        c = shape[i] + 1\n",
    "        idx_min = idx\n",
    "        idx_max = idx + r*c\n",
    "        W = vector[idx_min:idx_max].reshape(r,c)\n",
    "        weights.append(W)\n",
    "    return weights\n",
    "\n",
    "def eval_neural_network(weights, shape, X, y):\n",
    "    mse = np.asarray([])\n",
    "    for w in weights:\n",
    "        weights = vector_to_weights(w, shape)\n",
    "        nn = ann.MultiLayerPerceptron(shape, weights=weights)\n",
    "        y_pred = nn.run(X)\n",
    "        mse = np.append(mse, sklearn.metrics.mean_squared_error(np.atleast_2d(y), y_pred))\n",
    "    return mse\n",
    "\n",
    "def print_best_particle(best_particle):\n",
    "    print(\"New best particle found at iteration #{i} with mean squared error: {score}\".format(i=best_particle[0], score=best_particle[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#just xy error = 0.22938741634873416\n",
    "#with sinx sin y error = 0.2325498216710004\n",
    "#with sin and sq error = 0.21790465807135315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sine(X):\n",
    "    return np.sin(X)\n",
    "\n",
    "\n",
    "#loading Starts here\n",
    "\n",
    "def sq(X):\n",
    "    return np.power(X,2)\n",
    "num_classes = 2\n",
    "f = open(\"two_spirals.dat\",\"r\")\n",
    "data = np.loadtxt(f)\n",
    "\n",
    "# X = data[:,0:2]+sine(data[:,0:2])+sq(data[:,0:2])\n",
    "# #X = data[:,0:2]+sine(data[:,0:2])\n",
    "# #X = data[:,0:2]\n",
    "# y = data[:,2]\n",
    "# y = y.astype(int)\n",
    "# train_test_split = int(0.5*(len(X)))\n",
    "# #print(train_test_split)\n",
    "# X_train,X_test = X[:train_test_split],X[train_test_split:]\n",
    "# y_train,y_test = y[:train_test_split],y[train_test_split:]\n",
    "\n",
    "# print(len(X))\n",
    "# print(y.size)\n",
    "# print(y_train.size)\n",
    "# print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n",
      "264\n",
      "264\n",
      "132\n",
      "132\n",
      "[ 4.47485    -0.89004    -0.97192002 -0.77709692 20.02428252  0.7921712 ]\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0:2]\n",
    "test = np.zeros(shape=(len(X),6))\n",
    "\n",
    "for i in range(len(X)):\n",
    "   # print(X[i])\n",
    "    #print(sine(X[i]))\n",
    "    test[i] = np.append(X[i],[sine(X[i]),sq(X[i])])\n",
    "X=test\n",
    "y = data[:,2]\n",
    "y = y.astype(int)\n",
    "train_test_split = int(0.5*(len(y)))\n",
    "#print(train_test_split)\n",
    "X_train,X_test = X[:train_test_split],X[train_test_split:]\n",
    "y_train,y_test = y[:train_test_split],y[train_test_split:]\n",
    "\n",
    "\n",
    "print(len(test))\n",
    "print(len(X))\n",
    "print(y.size)\n",
    "print(y_train.size)\n",
    "print(y_test.size)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "print(y_train.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inputs =  6\n",
      "y test shap e=  (132,)\n",
      "y true shape =  (264, 2)\n",
      "y test true shape =  (132, 2)\n",
      "(132, 6)\n",
      "(132, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Load MNIST digits from sklearn\n",
    "\n",
    "# num_classes = 10\n",
    "# mnist = sklearn.datasets.load_digits(num_classes)\n",
    "# X, X_test, y, y_test = sklearn.model_selection.train_test_split(mnist.data, mnist.target)\n",
    "\n",
    "num_inputs = X.shape[1]\n",
    "print(\"Number of inputs = \",num_inputs)\n",
    "y_true = np.zeros((len(y), num_classes))\n",
    "\n",
    "for i in range(len(y)):\n",
    "    y_true[i, y[i]] = 1\n",
    "\n",
    "y_test_true = np.zeros((len(y_test), num_classes))\n",
    "for i in range(len(y_test)):\n",
    "    y_test_true[i, y_test[i]] = 1\n",
    "\n",
    "\n",
    "print(\"y test shap e= \", y_test.shape)\n",
    "print(\"y true shape = \",y_true.shape)\n",
    "print(\"y test true shape = \",y_test_true.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best particle found at iteration #0 with mean squared error: 0.4037024898701077\n",
      "New best particle found at iteration #100 with mean squared error: 0.21216305452025241\n",
      "New best particle found at iteration #200 with mean squared error: 0.2006584772461695\n",
      "New best particle found at iteration #300 with mean squared error: 0.18233487446101682\n",
      "New best particle found at iteration #400 with mean squared error: 0.1746649276578314\n",
      "New best particle found at iteration #500 with mean squared error: 0.16942572125038705\n",
      "New best particle found at iteration #600 with mean squared error: 0.16047439925846213\n",
      "New best particle found at iteration #700 with mean squared error: 0.15041963211983447\n",
      "New best particle found at iteration #800 with mean squared error: 0.1442599846612074\n",
      "New best particle found at iteration #900 with mean squared error: 0.13338956057853307\n",
      "New best particle found at iteration #1000 with mean squared error: 0.11575332882042053\n",
      "New best particle found at iteration #1100 with mean squared error: 0.10327386992755572\n",
      "New best particle found at iteration #1200 with mean squared error: 0.09982245675034797\n",
      "New best particle found at iteration #1300 with mean squared error: 0.08416499211344357\n",
      "New best particle found at iteration #1400 with mean squared error: 0.07922090979070788\n",
      "New best particle found at iteration #1500 with mean squared error: 0.07755285517718208\n",
      "New best particle found at iteration #1600 with mean squared error: 0.07582772443927163\n",
      "New best particle found at iteration #1700 with mean squared error: 0.07534531017387404\n",
      "New best particle found at iteration #1800 with mean squared error: 0.075099136732268\n",
      "New best particle found at iteration #1900 with mean squared error: 0.06899017796643636\n",
      "New best particle found at iteration #2000 with mean squared error: 0.06402952588460253\n",
      "New best particle found at iteration #2100 with mean squared error: 0.06335639791280177\n",
      "New best particle found at iteration #2200 with mean squared error: 0.06251389314348303\n",
      "New best particle found at iteration #2300 with mean squared error: 0.061841387764159275\n",
      "New best particle found at iteration #2400 with mean squared error: 0.06161719119962313\n",
      "New best particle found at iteration #2500 with mean squared error: 0.06107534910527929\n",
      "New best particle found at iteration #2600 with mean squared error: 0.060664157689960384\n",
      "New best particle found at iteration #2700 with mean squared error: 0.06034550012899818\n",
      "New best particle found at iteration #2800 with mean squared error: 0.060079728881444174\n",
      "New best particle found at iteration #2900 with mean squared error: 0.059876882194307805\n",
      "New best particle found at iteration #3000 with mean squared error: 0.05967542970600783\n",
      "New best particle found at iteration #3100 with mean squared error: 0.05956084228158644\n",
      "New best particle found at iteration #3200 with mean squared error: 0.059352838041758754\n",
      "New best particle found at iteration #3300 with mean squared error: 0.05892944198119226\n",
      "New best particle found at iteration #3400 with mean squared error: 0.05861241012804137\n",
      "New best particle found at iteration #3500 with mean squared error: 0.05841678275335169\n",
      "New best particle found at iteration #3600 with mean squared error: 0.05542621109642857\n",
      "New best particle found at iteration #3700 with mean squared error: 0.054606497393940016\n",
      "New best particle found at iteration #3800 with mean squared error: 0.05333295584685206\n",
      "New best particle found at iteration #3900 with mean squared error: 0.05136439616847072\n",
      "New best particle found at iteration #4000 with mean squared error: 0.05084085534905346\n",
      "MSE score = 0.07575757575757576\n",
      "Accuracy score =  0.9242424242424242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        66\n",
      "           1       1.00      0.85      0.92        66\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       132\n",
      "   macro avg       0.93      0.92      0.92       132\n",
      "weighted avg       0.93      0.92      0.92       132\n",
      " samples avg       0.92      0.92      0.92       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up\n",
    "\n",
    "shape = (num_inputs, 8, num_classes)\n",
    "\n",
    "cost_func = functools.partial(eval_neural_network, shape=shape, X=X, y=y_true.T)\n",
    "\n",
    "swarm = pso.ParticleSwarm(cost_func, num_dimensions=dim_weights(shape), num_particles=30,chi=0.72984 ,phi_p=2.02,phi_g=2.02)\n",
    "\n",
    "# Train...\n",
    "i = 0\n",
    "best_scores = [(i, swarm.best_score)]\n",
    "print_best_particle(best_scores[-1])\n",
    "while swarm.best_score>1e-6 and i<4000:\n",
    "    swarm._update()\n",
    "    i = i+1\n",
    "    #print(\"index = \",i)\n",
    "    if i%100==0 and swarm.best_score < best_scores[-1][1]:\n",
    "        best_scores.append((i, swarm.best_score))\n",
    "        print_best_particle(best_scores[-1])\n",
    "\n",
    "# Test...\n",
    "best_weights = vector_to_weights(swarm.g, shape)\n",
    "best_nn = ann.MultiLayerPerceptron(shape, weights=best_weights)\n",
    "\n",
    "y_test_pred = np.round(best_nn.run(X_test))\n",
    "print(\"MSE score =\",sklearn.metrics.mean_squared_error(y_test_true,y_test_pred.T))\n",
    "print(\"Accuracy score = \",sklearn.metrics.accuracy_score(y_test_true,y_test_pred.T))\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_test_true, y_test_pred.T))\n",
    "\n",
    "# #MES score = 0.30303030303030304\n",
    "# Accuracy score =  0.5606060606060606\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUsing the brute force method figure out the optimal functions\\n\\nthen use the same functions in PSO and compare it with base line\\n\\n'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Using the brute force method figure out the optimal functions\n",
    "\n",
    "then use the same functions in PSO and compare it with base line\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

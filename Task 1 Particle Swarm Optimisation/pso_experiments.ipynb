{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pso\n",
    "import ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_weights(shape):\n",
    "    dim = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        dim = dim + (shape[i] + 1) * shape[i+1]\n",
    "    return dim\n",
    "\n",
    "\n",
    "def weights_to_vector(weights):\n",
    "    w = np.asarray([])\n",
    "    for i in range(len(weights)):\n",
    "        v = weights[i].flatten()\n",
    "        w = np.append(w, v)\n",
    "    return w\n",
    "\n",
    "\n",
    "def vector_to_weights(vector, shape):\n",
    "    weights = []\n",
    "    idx = 0\n",
    "    for i in range(len(shape)-1):\n",
    "        r = shape[i+1]\n",
    "        c = shape[i] + 1\n",
    "        idx_min = idx\n",
    "        idx_max = idx + r*c\n",
    "        W = vector[idx_min:idx_max].reshape(r,c)\n",
    "        weights.append(W)\n",
    "    return weights\n",
    "\n",
    "\n",
    "#this is the optimisation for the coords of the particles??\n",
    "def eval_neural_network(weights, shape, X, y, activationLayer):\n",
    "    mse = np.asarray([])\n",
    "    for w in weights:\n",
    "        weights = vector_to_weights(w, shape)\n",
    "        nn = ann.MultiLayerPerceptron(shape, weights=weights)\n",
    "        y_pred = nn.run(X,activationLayer)\n",
    "        mse = np.append(mse, mean_squared_error(np.atleast_2d(y), y_pred))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def print_best_particle(best_particle):\n",
    "    print(\"New best particle found at iteration #{i} with mean squared error: {score}\".format(i=best_particle[0], score=best_particle[1]))\n",
    "\n",
    "\n",
    "def to_one_of_k(y):\n",
    "    num_inputs = 2\n",
    "    y_true = np.zeros((len(y), num_classes))\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        y_true[i, y[i]] = 1\n",
    "\n",
    "    y_test_true = np.zeros((len(y_test), num_classes))\n",
    "    for i in range(len(y_test)):\n",
    "        y_test_true[i, y_test[i]] = 1\n",
    "    \n",
    "    return y_true\n",
    "\n",
    "\n",
    "def twospirals(n_points, noise=.0, square=False, sine=False):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n_points = int(n_points/2)\n",
    "    n = np.sqrt( np.random.rand(n_points,1) ) * 780 * (2*np.pi)/360\n",
    "    d1x = -np.cos(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1y = np.sin(n)*n + np.random.rand(n_points,1) * noise\n",
    "    d1 = (d1x, d1y)\n",
    "    negd1 = (-d1x, -d1y)\n",
    "\n",
    "    if sine: \n",
    "        sinx1, sinx2 = np.sin(d1x), np.sin(d1y)\n",
    "        d1 += (sinx1, sinx2)\n",
    "        negd1 += (-sinx1, -sinx2)\n",
    "    if square:\n",
    "        sqx1, sqx2 = d1x*d1x, d1y*d1y\n",
    "        d1 += (sqx1, sqx2)\n",
    "        negd1 += (-sqx1, -sqx2)\n",
    "\n",
    "    x1 = np.hstack(d1)\n",
    "    x2 = np.hstack(negd1)\n",
    "    x = np.vstack( (x1, x2) )\n",
    "    y = np.hstack( ( np.zeros(n_points), np.ones(n_points) ) )\n",
    "    return (x, y.astype(int))\n",
    "    # (np.vstack( ( np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)) ) ), np.hstack((np.zeros(n_points),np.ones(n_points))))\n",
    "\n",
    "#just xy error = 0.22938741634873416\n",
    "#with sinx sin y error = 0.2325498216710004\n",
    "#with sin and sq error = 0.21790465807135315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, y_train = twospirals(n_points=100)\n",
    "X_test, y_test = twospirals(n_points=100)\n",
    "\n",
    "y_true_2d =  to_one_of_k(y=y_test) # to_one_of_k\n",
    "\n",
    "\n",
    "# X = X_train\n",
    "# y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "num_inputs = X_train.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = [0.51,0.49,0.6]\n",
    "print(np.round(array,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(shape, activationLayer):\n",
    "\n",
    "    cost_func = functools.partial(eval_neural_network, shape=shape, X=X, y=y_true.T,activationLayer=activationLayer)\n",
    "\n",
    "    swarm = pso.ParticleSwarm(cost_func, num_dimensions=dim_weights(shape), num_particles=25,chi=0.72984 ,phi_p=2.05,phi_g=2.05)\n",
    "    # Train...\n",
    "    i = 0\n",
    "    best_scores = [(i, swarm.best_score)]\n",
    "    print_best_particle(best_scores[-1])\n",
    "    \n",
    "    trainingLoss = []\n",
    "    testloss = []\n",
    "    iterations = 2000\n",
    "    while swarm.best_score>1e-6 and i<iterations:\n",
    "        swarm._update()\n",
    "        i = i+1\n",
    "        best_weights = vector_to_weights(swarm.g, shape)\n",
    "        best_nn = ann.MultiLayerPerceptron(shape, weights=best_weights)\n",
    "\n",
    "        y_test_pred =np.round(best_nn.run(X_test,activationLayer),0)\n",
    "        testError = sklearn.metrics.mean_squared_error(y_test_true,y_test_pred.T)\n",
    "        \n",
    "        #print(\"index = \",i)\n",
    "        if i%500==0 and swarm.best_score < best_scores[-1][1]:\n",
    "            best_scores.append((i, swarm.best_score))\n",
    "            print_best_particle(best_scores[-1])\n",
    "            #training per epoch\n",
    "            print(\"Mean absolute error score for index   =\",i,(activationLayer,testError))\n",
    "        trainingLoss.append(swarm.best_score)\n",
    "        testloss.append(testError)\n",
    "        \n",
    "    # Test...\n",
    "    \n",
    "    best_weights = vector_to_weights(swarm.g, shape)\n",
    "    best_nn = ann.MultiLayerPerceptron(shape, weights=best_weights)\n",
    "\n",
    "    y_test_pred =np.round(best_nn.run(X_test,activationLayer),0)\n",
    "    \n",
    "    points = np.arange(iterations)\n",
    "    plt.plot(points,testloss,color=\"b\",label=\"Test loss\")\n",
    "    plt.plot(points,trainingLoss,color=\"r\",label=\"Train loss\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(activationLayer)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    ##this is dumb\n",
    "    #eval neural network is pritning the mean squared error at each time\n",
    "    print(\"best score = \",best_scores[ -1])\n",
    "  #  print(sklearn.metrics.classification_report(y_test_true, y_test_pred.T))\n",
    "\n",
    "    print(\"Mean absolute error score for  =\",(activationLayer, sklearn.metrics.mean_squared_error(y_test_true,y_test_pred.T)))\n",
    "    #print(\"Accuracy score = \",sklearn.metrics.accuracy_score(y_test_true,y_test_pred.T))\n",
    "    return sklearn.metrics.mean_squared_error(y_test_true,y_test_pred.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=(num_inputs,6,num_classes)\n",
    "activationLayer=\"relu\"\n",
    "training(shape,activationLayer)\n",
    "# training(shape,\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testRun():\n",
    "    '''\n",
    "    I want mse to be y axis\n",
    "    I want neurons to be x axis\n",
    "    then I will have 3 plots, tanh, sigmoid and relu?\n",
    "    '''\n",
    "    #shape = (num_inputs, 8, num_classes)\n",
    "\n",
    "    activations = ['sigmoid','tanh']#,'relu','default']\n",
    "    neurons = [4,5,6,7,8]\n",
    "    arrays = np.zeros(shape=(len(activations),len(neurons)))\n",
    "\n",
    "    for i in range(len(arrays)):\n",
    "        activationLayer = activations[i]\n",
    "        for k in range(len(neurons)):\n",
    "            shape = (num_inputs,neurons[k],num_classes)\n",
    "            mse = training(shape,activationLayer)\n",
    "            arrays[i][k]=mse\n",
    "            print(i,k)\n",
    "     #   print(i)\n",
    "\n",
    "    return arrays\n",
    "\n",
    "arrays = testRun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def testRun():\n",
    "#     '''\n",
    "#     I want mse to be y axis\n",
    "#     I want neurons to be x axis\n",
    "#     then I will have 3 plots, tanh, sigmoid and relu?\n",
    "#     '''\n",
    "#     #shape = (num_inputs, 8, num_classes)\n",
    "\n",
    "#     activations = ['tanh']#,'relu','default']\n",
    "#     neurons = [4,5,6,7,8]\n",
    "#     arrays = np.zeros(shape=(len(activations),len(neurons)))\n",
    "\n",
    "#     for i in range(len(arrays)):\n",
    "#         activationLayer = activations[i]\n",
    "#         for k in range(len(neurons)):\n",
    "#             shape = (num_inputs,neurons[k],num_classes)\n",
    "#             mse = training(shape,activationLayer)\n",
    "#             arrays[i][k]=mse\n",
    "#             print(i,k)\n",
    "#      #   print(i)\n",
    "\n",
    "#     return arrays\n",
    "\n",
    "# tanh = testRun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "neurons = [4,5,6,7,8]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(neurons,arrays[1],color='r',label=\"tanh\")\n",
    "plt.plot(neurons,arrays[0],color='g',label=\"sigmoid\")\n",
    "#plt.plot(neurons,arrays[2],color='c',label=\"relu\")\n",
    "#plt.plot(neurons,arrays[3],color='b',label=\"Identity\")\n",
    "plt.xlabel(\"Neurons\")\n",
    "plt.ylabel(\"Test error: MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using the brute force method figure out the optimal functions\n",
    "\n",
    "then use the same functions in PSO and compare it with base line\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "neurons = [4,5,6,7,8]\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(neurons,arrays[1],color='r',label=\"tanh\")\n",
    "plt.plot(neurons,arrays[0],color='g',label=\"sigmoid\")\n",
    "#plt.plot(neurons,arrays[2],color='c',label=\"relu\")\n",
    "#plt.plot(neurons,arrays[3],color='b',label=\"Identity\")\n",
    "plt.xlabel(\"Neurons\")\n",
    "plt.ylabel(\"Test error: MSE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
